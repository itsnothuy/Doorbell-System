Copilot Coding Agent Instructions
This file provides guidance to the GitHub Copilot coding agent on how to implement the multi-pull‑request (PR) development effort for this project. The goal of this repository is to integrate the Frigate network video recorder (NVR) system into another application while preserving Frigate's core capabilities such as object detection, tracking, face recognition and optional generative‑AI descriptions. We will iterate on this integration slice by slice, creating small, reviewable PRs rather than one monolithic change. Each PR should map directly to one or more tasks defined in docs/planning.md and must adhere to the design decisions captured in the Architectural Decision Records (ADRs) within docs/adr.
High‑Level Objectives
* Preserve local processing. Frigate performs all object detection, tracking and face recognition on the local host, only calling out to cloud services when explicitly configured for generative descriptions【24†L155-L163】. Do not introduce any dependency on large language models (LLMs) for face identification - the face pipeline uses OpenCV's YuNet detector and the ArcFace/FaceNet embedding models【62†L164-L176】.
* Maintain a modular monolith. The existing Frigate architecture is a modular monolith: a single deployable service containing several internal modules connected via publish/subscribe queues【18†L197-L202】. Unless specifically instructed otherwise in an ADR, new functionality should fit into this pattern. For example, additional enrichments should be implemented as real‑time processors invoked by the EmbeddingsMaintainer.
* Incremental, test‑driven development. Each PR should compile, run the existing test suite, and ideally include new tests when adding features or refactoring code. CI must remain green (builds and tests pass) before a PR is merged.
* Clear documentation and PR summaries. For every PR, include a comprehensive description of what was implemented, why it was done and reference the relevant ADRs. Update the documentation in docs/ as needed.
Workflow
1. Understand the existing codebase. Before making changes, study the architecture overview in docs/architecture.md. It describes how frames are captured, how object detection is performed, how tracked objects are updated, and how enrichment processors such as face recognition and generative AI are invoked.
2. Follow the planning document. The file docs/planning.md breaks down the integration work into discrete slices. Each slice should be implemented in its own PR. Do not work on tasks out of order unless explicitly allowed by the planning document.
3. Respect ADRs. All design decisions are captured in docs/adr/*. If you find that a new approach is required (for example, extracting a microservice), write a new ADR and update the planning document before implementing the change.
4. Coding conventions. Use Python 3.10+ with type hints. Follow PEP 8 and maintain consistent formatting. Keep functions short and focused. Use descriptive variable names. Document public functions and modules with docstrings. Do not leave commented‑out code or dead references.
5. Testing. When modifying existing behaviour or adding new features, accompany your changes with unit or integration tests. If existing modules do not have tests yet, start by writing regression tests to document current behaviour. Ensure your code can run via pytest -q or an equivalent test command. Tests should exercise edge cases and error conditions where applicable.
6. Running and building. To build and run the Frigate server locally, use the commands documented in docs/building.md. Typically this involves creating a virtual environment, installing dependencies with pip install -r requirements.txt, and then launching the main entry point with python -m frigate. When working with the web UI, run the JavaScript build scripts as described in the docs. Your PR should not break local builds or Docker builds.
7. PR summaries and checklists. Your PR description must include:
8. A succinct summary of the implemented slice.
9. Links to the relevant ADR(s) and planning tasks.
10. A checklist verifying that code compiles, tests pass, documentation updates were made, and that privacy considerations (no telemetry leakage) were honoured.
11. Follow‑up tasks if further work is needed (e.g., TODO items).
12. Respect privacy. Do not add any analytics or telemetry. Face recognition embeddings and images must remain local as per the existing design【62†L173-L176】. When integrating generative AI, clearly mark where external calls occur and ensure that they are optional and require user‑supplied API keys.
Example Tasks for PRs
These are examples of slices you may encounter. Refer to docs/planning.md for the definitive list.
* Generate a call graph. Use static analysis or instrumentation to produce a call graph of the Frigate pipeline. Represent it in a Mermaid diagram and include it in docs/architecture.md.
* Add ADRs. Create ADR markdown files documenting key decisions such as using a modular monolith, selecting face embedding models, and integrating generative AI.
* Implement a new real‑time processor. For example, if the integration requires a new type of enrichment, implement it following the pattern used by FaceRealTimeProcessor and register it with the EmbeddingsMaintainer.
* Integrate with external APIs. When integrating generative AI or other services, encapsulate the API calls in their own module with robust error handling and testable interfaces. Use asynchronous requests where appropriate to avoid blocking the frame processing pipeline.
* Write tests and docs. After implementing features, update docs/architecture.md if the architecture changed, extend the planning file if new tasks are needed, and ensure there are tests covering the new behaviour.
By following these instructions and the accompanying documentation, the GitHub Copilot coding agent can incrementally build out the integration while preserving the robustness and privacy of Frigate's existing pipeline. Always consult the ADRs and planning document before making architectural changes.

